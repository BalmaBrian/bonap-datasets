{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import clear_output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os, csv, json, pandas, scrapy, multiprocessing\n",
    "from scrapy.crawler import CrawlerProcess"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if not os.path.exists('csv/'):\n",
    "  os.makedirs('csv/')\n",
    "\n",
    "if not os.path.exists('json_lines/'):\n",
    "  os.makedirs('json_lines/')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class BONAPSpider(scrapy.Spider):\n",
    "    name = 'bonap_spider'\n",
    "\n",
    "    def parse(self, response):\n",
    "        ID_COUNT = 0\n",
    "        TITLE_SELECTOR = '.page .h11 ::text'\n",
    "        TABLE_SELECTOR = '.page .tl'\n",
    "        HREF_SELECTOR = 'a ::attr(href)'\n",
    "        A_SELECTOR = './/tr/td/a'\n",
    "        ACCEPTED_TITLES = [\n",
    "            '\\r\\n(US County-Level Species Maps: List by Traditional Family)\\r\\n',\n",
    "            '\\r\\n(US County-Level Species Maps: List by Modern Family)\\r\\n',\n",
    "            '\\r\\n(State-Level Species Maps: List by Traditional Family)\\r\\n',\n",
    "            '\\r\\n(State-Level Species Maps: List by Modern Family)\\r\\n']\n",
    "\n",
    "        for title in response.css(TITLE_SELECTOR):\n",
    "            if title.extract() in ACCEPTED_TITLES:\n",
    "                TITLE_TAG = title.extract().replace('\\r\\n', '')\n",
    "            else:\n",
    "                table = scrapy.Selector(text=response.css(\n",
    "                    TABLE_SELECTOR).extract()[ID_COUNT])\n",
    "\n",
    "                yield {\n",
    "                    'ID': ID_COUNT,\n",
    "                    'TITLE TAG': TITLE_TAG,\n",
    "                    'FAMILY': title.extract(),\n",
    "                    'URI ARRAY': table.xpath(A_SELECTOR).css(HREF_SELECTOR).extract()\n",
    "                }\n",
    "                ID_COUNT += 1\n",
    "\n",
    "        ID_COUNT = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class BONAPMapSpider(scrapy.Spider):\n",
    "    name = 'bonap_map_spider'\n",
    "\n",
    "    def parse(self, response):\n",
    "        TITLE_SELECTOR = '._tfixed div ::text'\n",
    "        LINK_SELECTOR = '._tfixed a ::attr(href)'\n",
    "\n",
    "        for (title, link) in zip(response.css(TITLE_SELECTOR).extract(), response.css(LINK_SELECTOR).extract()):\n",
    "            yield {\n",
    "                'PLANT NAME': title,\n",
    "                'ROOT URL': response.url,\n",
    "                'URI': link\n",
    "            }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def spider_process(FEED_URI, spider, urls):\n",
    "    process = CrawlerProcess(settings={\n",
    "        'LOG_FILE': 'scrapy.log',\n",
    "        'FEED_URI': FEED_URI,\n",
    "        'FEED_FORMAT': 'jsonlines',\n",
    "    })\n",
    "    if spider == 'BONAPSpider':\n",
    "        process.crawl(BONAPSpider, start_urls=urls)\n",
    "    elif spider == 'BONAPMapSpider':\n",
    "        process.crawl(BONAPMapSpider, start_urls=urls)\n",
    "    process.start()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def prepend(list, str):\n",
    "    str += '{0}'\n",
    "    list = [str.format(i) for i in list]\n",
    "    return(list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "process_1 = multiprocessing.Process(target=spider_process, args=(\n",
    "    'json_lines/county_traditional_family_maps.jsonl', 'BONAPSpider', ['http://bonap.net/NAPA/Family/Traditional/County']))\n",
    "process_2 = multiprocessing.Process(target=spider_process, args=(\n",
    "    'json_lines/county_modern_family_maps.jsonl', 'BONAPSpider', ['http://bonap.net/NAPA/Family/Modern/County']))\n",
    "process_3 = multiprocessing.Process(target=spider_process, args=(\n",
    "    'json_lines/state_traditional_family_maps.jsonl', 'BONAPSpider', ['http://bonap.net/NAPA/Family/Traditional/State']))\n",
    "process_4 = multiprocessing.Process(target=spider_process, args=(\n",
    "    'json_lines/state_modern_family_maps.jsonl', 'BONAPSpider', ['http://bonap.net/NAPA/Family/Modern/State']))\n",
    "\n",
    "process_1.start()\n",
    "process_2.start()\n",
    "process_3.start()\n",
    "process_4.start()\n",
    "process_1.join()\n",
    "process_2.join()\n",
    "process_3.join()\n",
    "process_4.join()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "process_1_urls = []\n",
    "with open('json_lines/county_traditional_family_maps.jsonl', 'r') as open_file:\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        process_1_urls += data['URI ARRAY']\n",
    "    process_1_urls = prepend(process_1_urls, 'http://www.bonap.net')\n",
    "\n",
    "process_2_urls = []\n",
    "with open('json_lines/county_modern_family_maps.jsonl', 'r') as open_file:\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        process_2_urls += data['URI ARRAY']\n",
    "    process_2_urls = prepend(process_2_urls, 'http://www.bonap.net')\n",
    "\n",
    "process_3_urls = []\n",
    "with open('json_lines/state_traditional_family_maps.jsonl', 'r') as open_file:\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        process_3_urls += data['URI ARRAY']\n",
    "    process_3_urls = prepend(process_3_urls, 'http://www.bonap.net')\n",
    "\n",
    "process_4_urls = []\n",
    "with open('json_lines/state_modern_family_maps.jsonl', 'r') as open_file:\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        process_4_urls += data['URI ARRAY']\n",
    "    process_4_urls = prepend(process_4_urls, 'http://www.bonap.net')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "process_1 = multiprocessing.Process(target=spider_process, args=(\n",
    "    'json_lines/county_traditional_family_images.jsonl', 'BONAPMapSpider', process_1_urls))\n",
    "process_2 = multiprocessing.Process(target=spider_process, args=(\n",
    "    'json_lines/county_modern_family_images.jsonl', 'BONAPMapSpider', process_2_urls))\n",
    "process_3 = multiprocessing.Process(target=spider_process, args=(\n",
    "    'json_lines/state_traditional_family_images.jsonl', 'BONAPMapSpider', process_3_urls))\n",
    "process_4 = multiprocessing.Process(target=spider_process, args=(\n",
    "    'json_lines/state_modern_family_images.jsonl', 'BONAPMapSpider', process_4_urls))\n",
    "\n",
    "process_1.start()\n",
    "process_2.start()\n",
    "process_3.start()\n",
    "process_4.start()\n",
    "process_1.join()\n",
    "process_2.join()\n",
    "process_3.join()\n",
    "process_4.join()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('json_lines/county_traditional_family_images.jsonl', 'r') as open_file, open('csv/county_traditional_family_images.csv', 'w') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(['PLANT NAME', 'ROOT URL', 'URI'])\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        row = [data[map] for map in data.keys()]\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open('json_lines/county_modern_family_images.jsonl', 'r') as open_file, open('csv/county_modern_family_images.csv', 'w') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(['PLANT NAME', 'ROOT URL', 'URI'])\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        row = [data[map] for map in data.keys()]\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open('json_lines/county_traditional_family_maps.jsonl', 'r') as open_file, open('csv/county_traditional_family_maps.csv', 'w') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(['ID', 'TAG TITLE', 'FAMILY', 'URI ARRAY'])\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        row = [data[map] for map in data.keys()]\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open('json_lines/county_modern_family_maps.jsonl', 'r') as open_file, open('csv/county_modern_family_maps.csv', 'w') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(['ID', 'TAG TITLE', 'FAMILY', 'URI ARRAY'])\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        row = [data[map] for map in data.keys()]\n",
    "        writer.writerow(row)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('json_lines/state_traditional_family_images.jsonl', 'r') as open_file, open('csv/state_traditional_family_images.csv', 'w') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(['PLANT NAME', 'ROOT URL', 'URI'])\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        row = [data[map] for map in data.keys()]\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open('json_lines/state_modern_family_images.jsonl', 'r') as open_file, open('csv/state_modern_family_images.csv', 'w') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(['PLANT NAME', 'ROOT URL', 'URI'])\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        row = [data[map] for map in data.keys()]\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open('json_lines/state_traditional_family_maps.jsonl', 'r') as open_file, open('csv/state_traditional_family_maps.csv', 'w') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(['ID', 'TAG TITLE', 'FAMILY', 'URI ARRAY'])\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        row = [data[map] for map in data.keys()]\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open('json_lines/state_modern_family_maps.jsonl', 'r') as open_file, open('csv/state_modern_family_maps.csv', 'w') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(['ID', 'TAG TITLE', 'FAMILY', 'URI ARRAY'])\n",
    "    for line in open_file:\n",
    "        data = json.loads(line)\n",
    "        row = [data[map] for map in data.keys()]\n",
    "        writer.writerow(row)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "county_traditional_family_images = pandas.read_csv(\n",
    "    'csv/county_traditional_family_images.csv')\n",
    "county_modern_family_images = pandas.read_csv(\n",
    "    'csv/county_modern_family_images.csv')\n",
    "county_traditional_family_maps = pandas.read_csv(\n",
    "    'csv/county_traditional_family_maps.csv')\n",
    "county_modern_family_maps = pandas.read_csv(\n",
    "    'csv/county_modern_family_maps.csv')\n",
    "\n",
    "state_traditional_family_images = pandas.read_csv(\n",
    "    'csv/state_traditional_family_images.csv')\n",
    "state_modern_family_images = pandas.read_csv(\n",
    "    'csv/state_modern_family_images.csv')\n",
    "state_traditional_family_maps = pandas.read_csv(\n",
    "    'csv/state_traditional_family_maps.csv')\n",
    "state_modern_family_maps = pandas.read_csv(\n",
    "    'csv/state_modern_family_maps.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "county_traditional_family_maps['URL ARRAY'] = county_traditional_family_maps['URI ARRAY']\n",
    "county_modern_family_maps['URL ARRAY'] = county_modern_family_maps['URI ARRAY']\n",
    "state_traditional_family_maps['URL ARRAY'] = state_traditional_family_maps['URI ARRAY']\n",
    "state_modern_family_maps['URL ARRAY'] = state_modern_family_maps['URI ARRAY']\n",
    "\n",
    "for index in range(county_traditional_family_maps['URL ARRAY'].size):\n",
    "  array = json.loads(county_traditional_family_maps['URL ARRAY'][index].replace(\"'\", '\"'))\n",
    "  county_traditional_family_maps['URL ARRAY'][index] = prepend(array, 'http://www.bonap.net')\n",
    "for index in range(county_modern_family_maps['URL ARRAY'].size):\n",
    "  array = json.loads(county_modern_family_maps['URL ARRAY'][index].replace(\"'\", '\"'))\n",
    "  county_modern_family_maps['URL ARRAY'][index] = prepend(array, 'http://www.bonap.net')\n",
    "for index in range(state_traditional_family_maps['URL ARRAY'].size):\n",
    "  array = json.loads(state_traditional_family_maps['URL ARRAY'][index].replace(\"'\", '\"'))\n",
    "  state_traditional_family_maps['URL ARRAY'][index] = prepend(array, 'http://www.bonap.net')\n",
    "for index in range(state_modern_family_maps['URL ARRAY'].size):\n",
    "  array = json.loads(state_modern_family_maps['URL ARRAY'][index].replace(\"'\", '\"'))\n",
    "  state_modern_family_maps['URL ARRAY'][index] = prepend(array, 'http://www.bonap.net')\n",
    "\n",
    "clear_output()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def family(index, column, maps):\n",
    "    for (url, family_name) in zip(maps['URL ARRAY'], maps['FAMILY']):\n",
    "        if column[index] in url:\n",
    "            return family_name\n",
    "        return ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "family_list = []\n",
    "for index in range(county_traditional_family_images['ROOT URL'].size):\n",
    "    family_list.append(\n",
    "        family(index, county_traditional_family_images['ROOT URL'], county_traditional_family_maps))\n",
    "county_traditional_family_images['FAMILY'] = family_list\n",
    "\n",
    "family_list = []\n",
    "for index in range(county_modern_family_images['ROOT URL'].size):\n",
    "    family_list.append(\n",
    "        family(index, county_modern_family_images['ROOT URL'], county_modern_family_maps))\n",
    "county_modern_family_images['FAMILY'] = family_list\n",
    "\n",
    "family_list = []\n",
    "for index in range(state_traditional_family_images['ROOT URL'].size):\n",
    "    family_list.append(\n",
    "        family(index, state_traditional_family_images['ROOT URL'], state_traditional_family_maps))\n",
    "state_traditional_family_images['FAMILY'] = family_list\n",
    "\n",
    "family_list = []\n",
    "for index in range(state_modern_family_images['ROOT URL'].size):\n",
    "    family_list.append(\n",
    "        family(index, state_modern_family_images['ROOT URL'], state_modern_family_maps))\n",
    "state_modern_family_images['FAMILY'] = family_list"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "afb6a6c78f6a7fe7440d6d9275ba7f7849b945e855d424e2bc8c0544a1b78df5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}